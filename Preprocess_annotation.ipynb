{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkW6gyusbafN47PRlUfX58"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Import library**"],"metadata":{"id":"oruShWlWO5xA"}},{"cell_type":"code","source":["import json\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","import os\n","from collections import defaultdict\n","import copy\n","from collections import Counter"],"metadata":{"id":"hknY-jo-O-XV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount= True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UiQOiwfnO1UO","executionInfo":{"status":"ok","timestamp":1766835010215,"user_tz":-420,"elapsed":16111,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"84f134a5-8ea8-43b3-a929-5b6623190c2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**Load image annotation**"],"metadata":{"id":"K7Mz-63CKEDH"}},{"cell_type":"code","source":["with open('/content/drive/MyDrive/New_BBox_Dataset/coco_annotation/cleaned/left_out_cha_mieng/tofu_separated_final.json', 'r', encoding='utf-8') as f:\n","    data_tofu = json.load(f)"],"metadata":{"id":"_HvUwZWLVA2Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/New_BBox_Dataset/coco_annotation/cleaned/left_out_cha_mieng/cha_ca_phuc_separated_final.json', 'r', encoding='utf-8') as f:\n","    data_cha_ca = json.load(f)"],"metadata":{"id":"fZDanMLnSXyO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/New_BBox_Dataset/coco_annotation/cleaned/left_out_cha_mieng/suon_separated_2_final.json', 'r', encoding='utf-8') as f:\n","    data_suon = json.load(f)"],"metadata":{"id":"omaNYyU-SZGl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Config file_name**"],"metadata":{"id":"tgveBUkq0Gbi"}},{"cell_type":"code","source":["def remove_filename_prefix(coco_dict, prefix=\"Suon/\"):\n","\n","    count = 0\n","\n","    for img in coco_dict['images']:\n","        if img['file_name'].startswith(prefix):\n","\n","            old_name = img['file_name']\n","            new_name = old_name.replace(prefix, \"\", 1)\n","\n","            img['file_name'] = new_name\n","            count += 1\n","\n","            if count <= 3:\n","                print(f\"Đã sửa: '{old_name}' -> '{new_name}'\")\n","\n","    print(f\"--- Hoàn tất! Đã sửa đường dẫn cho {count} ảnh. ---\")\n","    return coco_dict\n","\n","data_suon = remove_filename_prefix(data_suon, prefix=\"Suon/\")\n","\n","if data_suon['images']:\n","    print(\"Ví dụ sau khi sửa:\", data_suon['images'][0]['file_name'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10dd-IDr0Lyi","executionInfo":{"status":"ok","timestamp":1766835082087,"user_tz":-420,"elapsed":14,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"c1899fc6-7611-46f5-a4f9-85b1b0a7588b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Hoàn tất! Đã sửa đường dẫn cho 0 ảnh. ---\n","Ví dụ sau khi sửa: suon_cot_let_100.jpg\n"]}]},{"cell_type":"code","source":["def remove_empty_images(coco_dict):\n","    \"\"\"\n","    Xóa các image trong coco_dict nếu image đó không có annotation nào.\n","    \"\"\"\n","\n","    annotated_image_ids = {ann['image_id'] for ann in coco_dict['annotations']}\n","\n","    original_count = len(coco_dict['images'])\n","\n","    coco_dict['images'] = [\n","        img for img in coco_dict['images']\n","        if img['id'] in annotated_image_ids\n","    ]\n","\n","    new_count = len(coco_dict['images'])\n","\n","    print(f\"Đã xử lý xong!\")\n","    print(f\"Trước khi lọc: {original_count} ảnh\")\n","    print(f\"Sau khi lọc:   {new_count} ảnh\")\n","    print(f\"Đã xóa:        {original_count - new_count} ảnh rỗng\")\n","\n","    return coco_dict"],"metadata":{"id":"Oq_XvGDnSVW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_tofu = remove_empty_images(data_tofu)\n","data_cha_ca = remove_empty_images(data_cha_ca)\n","data_suon = remove_empty_images(data_suon)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UrjVBS1tSwIl","executionInfo":{"status":"ok","timestamp":1766835099928,"user_tz":-420,"elapsed":6,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"49079fcc-9950-459a-8c9e-a5128a553176"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Đã xử lý xong!\n","Trước khi lọc: 209 ảnh\n","Sau khi lọc:   209 ảnh\n","Đã xóa:        0 ảnh rỗng\n","Đã xử lý xong!\n","Trước khi lọc: 200 ảnh\n","Sau khi lọc:   200 ảnh\n","Đã xóa:        0 ảnh rỗng\n","Đã xử lý xong!\n","Trước khi lọc: 329 ảnh\n","Sau khi lọc:   329 ảnh\n","Đã xóa:        0 ảnh rỗng\n"]}]},{"cell_type":"markdown","source":["**Concat dataset (suon_non -> suon_cot_let -> cha_cat_lat->cha_mieng->tofu_chien->tofu_trang)**"],"metadata":{"id":"c6sQae9YKSVu"}},{"cell_type":"code","source":["def merge_list_of_coco_dicts(dict_list):\n","    if not dict_list:\n","        return {}\n","\n","    merged_dict = {\n","        'info': dict_list[0].get('info', {}),\n","        'licenses': dict_list[0].get('licenses', []),\n","        'images': [],\n","        'annotations': [],\n","        'categories': []\n","    }\n","\n","    global_cat_name_to_id = {}\n","    next_global_cat_id = 1\n","\n","    current_img_offset = 0\n","    current_ann_offset = 0\n","\n","    print(f\"Bắt đầu gộp {len(dict_list)} datasets...\")\n","\n","    for i, sub_dict in enumerate(dict_list):\n","\n","        local_to_global_cat_id = {}\n","\n","        for cat in sub_dict.get('categories', []):\n","            name = cat['name']\n","            if name not in global_cat_name_to_id:\n","                global_cat_name_to_id[name] = next_global_cat_id\n","\n","                new_cat = cat.copy()\n","                new_cat['id'] = next_global_cat_id\n","                merged_dict['categories'].append(new_cat)\n","\n","                next_global_cat_id += 1\n","\n","            local_to_global_cat_id[cat['id']] = global_cat_name_to_id[name]\n","\n","        max_id_in_this_batch = 0\n","\n","        for img in sub_dict.get('images', []):\n","            new_img = img.copy()\n","            new_img['id'] = img['id'] + current_img_offset\n","            merged_dict['images'].append(new_img)\n","\n","            if img['id'] > max_id_in_this_batch:\n","                max_id_in_this_batch = img['id']\n","\n","        max_ann_id_in_this_batch = 0\n","\n","        for ann in sub_dict.get('annotations', []):\n","            new_ann = ann.copy()\n","\n","            new_ann['id'] = ann['id'] + current_ann_offset\n","\n","            new_ann['image_id'] = ann['image_id'] + current_img_offset\n","\n","            if ann['category_id'] in local_to_global_cat_id:\n","                new_ann['category_id'] = local_to_global_cat_id[ann['category_id']]\n","            else:\n","                continue\n","\n","            merged_dict['annotations'].append(new_ann)\n","\n","            if ann['id'] > max_ann_id_in_this_batch:\n","                max_ann_id_in_this_batch = ann['id']\n","\n","        current_img_offset += max_id_in_this_batch\n","        current_ann_offset += max_ann_id_in_this_batch\n","\n","        print(f\" -> Đã gộp dict #{i+1}: Thêm {len(sub_dict.get('images', []))} ảnh.\")\n","\n","    return merged_dict"],"metadata":{"id":"RpmKINiYUypV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_dicts = [data_suon, data_cha_ca, data_tofu]\n","\n","final_dataset = merge_list_of_coco_dicts(all_dicts)\n","\n","print(f\"Tổng categories: {len(final_dataset['categories'])}\")\n","print(f\"Tổng images: {len(final_dataset['images'])}\")\n","print(f\"Tổng annotations: {len(final_dataset['annotations'])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m31tzYQCWASd","executionInfo":{"status":"ok","timestamp":1766835134159,"user_tz":-420,"elapsed":9,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"0b20bb19-6a77-471c-bcba-175bfe12eae7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Bắt đầu gộp 3 datasets...\n"," -> Đã gộp dict #1: Thêm 329 ảnh.\n"," -> Đã gộp dict #2: Thêm 200 ảnh.\n"," -> Đã gộp dict #3: Thêm 209 ảnh.\n","Tổng categories: 6\n","Tổng images: 738\n","Tổng annotations: 3137\n"]}]},{"cell_type":"code","source":["def analyze_coco_class_distribution(coco_dict):\n","\n","    stats = {}\n","\n","    for cat in coco_dict['categories']:\n","        stats[cat['id']] = {\n","            'name': cat['name'],\n","            'ann_count': 0,\n","            'image_ids': set()\n","        }\n","\n","    for ann in coco_dict['annotations']:\n","        cat_id = ann['category_id']\n","        image_id = ann['image_id']\n","\n","        if cat_id in stats:\n","            stats[cat_id]['ann_count'] += 1\n","            stats[cat_id]['image_ids'].add(image_id)\n","\n","    print(f\"{'ID':<5} | {'Class Name':<25} | {'Anns':<8} | {'Images':<8}\")\n","    print(\"-\" * 55)\n","\n","    sorted_stats = sorted(stats.items(), key=lambda x: x[1]['ann_count'], reverse=True)\n","\n","    total_anns = 0\n","\n","    for cat_id, data in sorted_stats:\n","        img_count = len(data['image_ids'])\n","        print(f\"{cat_id:<5} | {data['name']:<25} | {data['ann_count']:<8} | {img_count:<8}\")\n","        total_anns += data['ann_count']\n","\n","    print(\"-\" * 55)\n","    print(f\"Total Annotations: {total_anns}\")\n","    print(f\"Total Categories:  {len(stats)}\")\n","\n","analyze_coco_class_distribution(final_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEEBSc_9413q","executionInfo":{"status":"ok","timestamp":1766835143743,"user_tz":-420,"elapsed":9,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"690fb81c-2185-4198-b1e6-af12a852fc6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ID    | Class Name                | Anns     | Images  \n","-------------------------------------------------------\n","3     | cha_cat_lat               | 781      | 159     \n","5     | tofu_chien                | 744      | 117     \n","6     | tofu_trang                | 572      | 118     \n","4     | cha_mieng                 | 495      | 77      \n","1     | suon_non                  | 291      | 144     \n","2     | suon_cot_let              | 254      | 193     \n","-------------------------------------------------------\n","Total Annotations: 3137\n","Total Categories:  6\n"]}]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/New_BBox_Dataset/merged_coco_version/ver_6/merged_coco_v6_left_out_cha_mieng_fix_cha_ca.json', 'w', encoding='utf-8') as f:\n","    json.dump(final_dataset, f, ensure_ascii=False, indent=4)"],"metadata":{"id":"MQlux5JEWbdV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Split metadata dict to train/val/test**"],"metadata":{"id":"3vEdBwjjL0Nf"}},{"cell_type":"code","source":["import json\n","import pandas as pd\n","import random\n","\n","def split_dataset_stratified_v5(list_cha_ca, list_tofu, list_suon, val_ratio=0.1, test_ratio=0.1):\n","\n","    all_data = []\n","\n","    def get_subclass(filename):\n","        keywords = [\n","            'cha_cat_lat', 'cha_mieng',\n","            'tofu_trang', 'tofu_chien',\n","            'suon_non', 'suon_cot_let', 'suon_cotlet', 'chaca_catlat'\n","        ]\n","        for kw in keywords:\n","            if kw in filename:\n","                if kw == 'suon_cotlet': return 'suon_cot_let'\n","                if kw == 'chaca_catlat': return 'cha_cat_lat'\n","                return kw\n","        return \"unknown\"\n","\n","    all_lists = list_cha_ca + list_tofu + list_suon\n","\n","    temp_data = []\n","    for item in all_lists:\n","        sub_class = get_subclass(item['id_anh'])\n","\n","        img_attrs = item.get('image_attributes', {})\n","        food_attrs = item.get('food_attributes', {})\n","\n","        difficulty = img_attrs.get('difficulty_level', 'Unknown_Diff')\n","\n","        context = (\n","            food_attrs.get('dish_context') or\n","            food_attrs.get('dish_variant') or\n","            food_attrs.get('interaction_state') or\n","            'Unknown_Ctx'\n","        )\n","\n","        temp_data.append({\n","            'data': item,\n","            'sub_class': sub_class,\n","            'difficulty': difficulty,\n","            'context': context,\n","\n","            'key_level_1': f\"{sub_class}|{difficulty}|{context}\",\n","\n","            'key_level_2': f\"{sub_class}|{difficulty}\",\n","\n","            'key_level_3': f\"{sub_class}\"\n","        })\n","\n","    df = pd.DataFrame(temp_data)\n","\n","    counts_L1 = df['key_level_1'].value_counts()\n","\n","    def get_final_stratify_key(row):\n","        if counts_L1.get(row['key_level_1'], 0) >= 3:\n","            return row['key_level_1']\n","        return row['key_level_2']\n","\n","    df['final_key'] = df.apply(get_final_stratify_key, axis=1)\n","\n","    counts_Final = df['final_key'].value_counts()\n","\n","    def fallback_to_level_3(row):\n","        if counts_Final.get(row['final_key'], 0) >= 3:\n","            return row['final_key']\n","        return row['key_level_3']\n","\n","    df['final_key'] = df.apply(fallback_to_level_3, axis=1)\n","\n","    train_set, val_set, test_set = [], [], []\n","    unique_groups = df['final_key'].unique()\n","\n","    print(f\"{'Stratify Group (v5)':<50} | {'Total':<5} | {'Tr':<3} | {'Va':<3} | {'Te':<3}\")\n","    print(\"-\" * 80)\n","\n","    for group_name in unique_groups:\n","        group_items = df[df['final_key'] == group_name]['data'].tolist()\n","        total_count = len(group_items)\n","\n","        random.seed(42)\n","        random.shuffle(group_items)\n","\n","        if total_count == 1:\n","            train_set.extend(group_items)\n","            n_val, n_test = 0, 0\n","\n","        elif total_count == 2:\n","            train_set.append(group_items[0])\n","            val_set.append(group_items[1])\n","            n_val, n_test = 1, 0\n","\n","        else:\n","            n_val = max(1, int(round(total_count * val_ratio)))\n","            n_test = max(1, int(round(total_count * test_ratio)))\n","\n","            if total_count - n_val - n_test < 1:\n","                if n_test > 0: n_test -= 1\n","                elif n_val > 0: n_val -= 1\n","\n","            test_set.extend(group_items[:n_test])\n","            val_set.extend(group_items[n_test : n_test + n_val])\n","            train_set.extend(group_items[n_test + n_val :])\n","\n","        short_name = (group_name[:47] + '..') if len(group_name) > 49 else group_name\n","        tr_c = len(group_items) - n_val - n_test if total_count > 2 else (1 if total_count > 0 else 0)\n","        va_c = n_val if total_count > 2 else (1 if total_count == 2 else 0)\n","        te_c = n_test if total_count > 2 else 0\n","\n","        print(f\"{short_name:<50} | {total_count:<5} | {tr_c:<3} | {va_c:<3} | {te_c:<3}\")\n","\n","    return {\"train\": train_set, \"val\": val_set, \"test\": test_set}\n","\n","with open('/content/drive/MyDrive/Data MetaData/left_out_cha_mieng/cha_ca_v2_filter_2_final.json', 'r', encoding='utf-8') as f:\n","    list_cha_ca_raw = json.load(f)\n","with open('/content/drive/MyDrive/Data MetaData/left_out_cha_mieng/tofu_filter_final.json', 'r', encoding='utf-8') as f:\n","    list_tofu_raw = json.load(f)\n","with open('/content/drive/MyDrive/Data MetaData/left_out_cha_mieng/suon_v2_filter_final.json', 'r', encoding='utf-8') as f:\n","    list_suon_raw = json.load(f)\n","\n","datasets = split_dataset_stratified_v5(list_cha_ca_raw, list_tofu_raw, list_suon_raw)\n","\n","print(f\"\\nTổng ảnh Train: {len(datasets['train'])}\")\n","print(f\"Tổng ảnh Val:   {len(datasets['val'])}\")\n","print(f\"Tổng ảnh Test:  {len(datasets['test'])}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fb6lYVSXYZ1","executionInfo":{"status":"ok","timestamp":1766835262476,"user_tz":-420,"elapsed":1037,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"63f90641-ed94-4a8f-d2aa-749a9077e16b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Stratify Group (v5)                                | Total | Tr  | Va  | Te \n","--------------------------------------------------------------------------------\n","cha_cat_lat|Medium|Surface_Topping_Arrangement     | 62    | 50  | 6   | 6  \n","cha_cat_lat|Easy|Surface_Topping_Arrangement       | 64    | 52  | 6   | 6  \n","cha_mieng|Medium|Shallow_Braised_Bathing           | 3     | 1   | 1   | 1  \n","cha_mieng|Medium|Solid_Dry_Stacked                 | 14    | 12  | 1   | 1  \n","cha_cat_lat|Easy|Solid_Dry_Stacked                 | 7     | 5   | 1   | 1  \n","cha_mieng|Easy|Solid_Dry_Stacked                   | 12    | 10  | 1   | 1  \n","cha_mieng|Hard|Solid_Dry_Stacked                   | 6     | 4   | 1   | 1  \n","cha_mieng|Easy|Shallow_Braised_Bathing             | 6     | 4   | 1   | 1  \n","cha_cat_lat|Hard|Surface_Topping_Arrangement       | 14    | 12  | 1   | 1  \n","cha_cat_lat                                        | 1     | 1   | 0   | 0  \n","cha_mieng                                          | 4     | 2   | 1   | 1  \n","cha_cat_lat|Hard|Solid_Dry_Stacked                 | 3     | 1   | 1   | 1  \n","cha_cat_lat|Medium|Solid_Dry_Stacked               | 4     | 2   | 1   | 1  \n","tofu_trang|Medium|Plain_Dry_Item                   | 44    | 36  | 4   | 4  \n","tofu_chien|Hard|Plain_Dry_Item                     | 16    | 12  | 2   | 2  \n","tofu_chien|Medium|Plain_Dry_Item                   | 54    | 44  | 5   | 5  \n","tofu_chien                                         | 1     | 1   | 0   | 0  \n","tofu_chien|Easy|Plain_Dry_Item                     | 31    | 25  | 3   | 3  \n","tofu_trang|Easy|Plain_Dry_Item                     | 37    | 29  | 4   | 4  \n","tofu_trang|Hard|Plain_Dry_Item                     | 14    | 12  | 1   | 1  \n","tofu_chien|Hard|Sauce_Topping_Complex              | 4     | 2   | 1   | 1  \n","tofu_trang|Hard|Sauce_Topping_Complex              | 6     | 4   | 1   | 1  \n","tofu_trang                                         | 2     | 1   | 1   | 0  \n","suon_non|Medium|Com_Tam_Assembly                   | 40    | 32  | 4   | 4  \n","suon_cot_let|Easy|Com_Tam_Assembly                 | 48    | 38  | 5   | 5  \n","suon_non|Easy|Com_Tam_Assembly                     | 23    | 19  | 2   | 2  \n","suon_cot_let|Medium|Com_Tam_Assembly               | 39    | 31  | 4   | 4  \n","suon_non|Hard|Com_Tam_Assembly                     | 22    | 18  | 2   | 2  \n","suon_cot_let|Hard|Com_Tam_Assembly                 | 21    | 17  | 2   | 2  \n","suon_non|Medium|Isolated_Item                      | 20    | 16  | 2   | 2  \n","suon_non|Hard|Isolated_Item                        | 12    | 10  | 1   | 1  \n","suon_cot_let|Hard|Isolated_Item                    | 14    | 12  | 1   | 1  \n","suon_non|Easy|Isolated_Item                        | 26    | 20  | 3   | 3  \n","suon_cot_let|Medium|Isolated_Item                  | 18    | 14  | 2   | 2  \n","suon_cot_let|Easy|Isolated_Item                    | 46    | 36  | 5   | 5  \n","\n","Tổng ảnh Train: 585\n","Tổng ảnh Val:   77\n","Tổng ảnh Test:  76\n"]}]},{"cell_type":"code","source":["def check_annotation_balance(dataset_dict, dataset_name=\"Train\"):\n","    \"\"\"\n","    Hàm kiểm tra xem sau khi split, số lượng annotation có bị lệch không.\n","    \"\"\"\n","    class_counts = {}\n","    total_imgs = len(dataset_dict)\n","    total_anns = 0\n","\n","    for item in dataset_dict:\n","        pass\n","\n","    print(f\"--- Kiểm tra tập {dataset_name} ({total_imgs} ảnh) ---\")\n","\n","def verify_difficulty_distribution(dataset, name):\n","    from collections import Counter\n","    diffs = [item.get('image_attributes', {}).get('difficulty_level', 'Unknown') for item in dataset]\n","    counts = Counter(diffs)\n","    total = sum(counts.values())\n","    print(f\"\\nPhân phối độ khó tập {name} ({total} ảnh):\")\n","    for k, v in counts.items():\n","        print(f\"  - {k}: {v} ({v/total*100:.1f}%)\")\n","\n","# Gọi hàm kiểm tra\n","verify_difficulty_distribution(datasets['train'], \"TRAIN\")\n","verify_difficulty_distribution(datasets['val'], \"VAL\")\n","verify_difficulty_distribution(datasets['test'], \"TEST\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yn_j4pyyaMhy","executionInfo":{"status":"ok","timestamp":1766835276934,"user_tz":-420,"elapsed":18,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"7adeaaab-ae2d-46df-b82e-1c13c5e59e84"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Phân phối độ khó tập TRAIN (585 ảnh):\n","  - Medium: 241 (41.2%)\n","  - Easy: 239 (40.9%)\n","  - Hard: 105 (17.9%)\n","\n","Phân phối độ khó tập VAL (77 ảnh):\n","  - Medium: 32 (41.6%)\n","  - Easy: 31 (40.3%)\n","  - Hard: 14 (18.2%)\n","\n","Phân phối độ khó tập TEST (76 ảnh):\n","  - Medium: 30 (39.5%)\n","  - Easy: 31 (40.8%)\n","  - Hard: 15 (19.7%)\n"]}]},{"cell_type":"code","source":["train_json = datasets['train']\n","val_json = datasets['val']\n","test_json = datasets['test']\n","\n","with open('/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/train_split.json', 'w') as f: json.dump(train_json, f)\n","with open('/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/val_split.json', 'w') as f: json.dump(val_json, f)\n","with open('/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/test_split.json', 'w') as f: json.dump(test_json, f)"],"metadata":{"id":"6e87u7UH-2vf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_and_combine_splits(train_path, val_path, test_path):\n","    \"\"\"\n","    Đọc 3 file JSON (Train, Val, Test) và gộp vào một dictionary.\n","    \"\"\"\n","    final_dataset = {\n","        \"train\": [],\n","        \"val\": [],\n","        \"test\": []\n","    }\n","\n","    try:\n","        print(f\"Đang đọc file Train: {train_path}...\")\n","        with open(train_path, 'r', encoding='utf-8') as f:\n","            final_dataset[\"train\"] = json.load(f)\n","\n","        print(f\"Đang đọc file Val: {val_path}...\")\n","        with open(val_path, 'r', encoding='utf-8') as f:\n","            final_dataset[\"val\"] = json.load(f)\n","\n","        print(f\"Đang đọc file Test: {test_path}...\")\n","        with open(test_path, 'r', encoding='utf-8') as f:\n","            final_dataset[\"test\"] = json.load(f)\n","\n","        print(\"\\n--- ĐÃ LOAD DỮ LIỆU THÀNH CÔNG ---\")\n","        print(f\"Số lượng Train: {len(final_dataset['train'])}\")\n","        print(f\"Số lượng Val:   {len(final_dataset['val'])}\")\n","        print(f\"Số lượng Test:  {len(final_dataset['test'])}\")\n","\n","        return final_dataset\n","\n","    except FileNotFoundError as e:\n","        print(f\"\\nLỖI: Không tìm thấy file. Vui lòng kiểm tra lại đường dẫn.\\nChi tiết: {e}\")\n","        return None\n","    except json.JSONDecodeError as e:\n","        print(f\"\\nLỖI: File không đúng định dạng JSON.\\nChi tiết: {e}\")\n","        return None"],"metadata":{"id":"j2QsvTb-Ar2P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_train = '/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/train_split.json'\n","path_val   = '/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/val_split.json'\n","path_test  = '/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/test_split.json'\n","\n","datasets = load_and_combine_splits(path_train, path_val, path_test)"],"metadata":{"id":"XlWxN6k6As6p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1766835390807,"user_tz":-420,"elapsed":26,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"dd164009-76fa-418a-be5c-f3a5c65d8d47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Đang đọc file Train: /content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/train_split.json...\n","Đang đọc file Val: /content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/val_split.json...\n","Đang đọc file Test: /content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/left_out_cha_mieng_fix_cha_ca/test_split.json...\n","\n","--- ĐÃ LOAD DỮ LIỆU THÀNH CÔNG ---\n","Số lượng Train: 585\n","Số lượng Val:   77\n","Số lượng Test:  76\n"]}]},{"cell_type":"markdown","source":["**Split coco format data to train/val/test**"],"metadata":{"id":"1VUC-TeeMCB3"}},{"cell_type":"code","source":["import json\n","import os\n","from collections import defaultdict\n","\n","def create_coco_subsets(master_coco_path, split_datasets, output_dir):\n","\n","    print(f\"Đang đọc file gốc: {master_coco_path} ...\")\n","    with open(master_coco_path, 'r', encoding='utf-8') as f:\n","        coco_data = json.load(f)\n","\n","    filename_to_img = {img['file_name']: img for img in coco_data['images']}\n","\n","    img_id_to_anns = defaultdict(list)\n","    if 'annotations' in coco_data:\n","        for ann in coco_data['annotations']:\n","            img_id_to_anns[ann['image_id']].append(ann)\n","\n","    categories = coco_data.get('categories', [])\n","    info = coco_data.get('info', {})\n","    licenses = coco_data.get('licenses', [])\n","\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for phase in ['train', 'val', 'test']:\n","        print(f\"--> Đang xử lý tập: {phase.upper()}\")\n","\n","        target_filenames = set([item['id_anh'] for item in split_datasets[phase]])\n","\n","        new_images = []\n","        new_annotations = []\n","\n","        missing_count = 0\n","\n","        for fname in target_filenames:\n","            if fname in filename_to_img:\n","                img_info = filename_to_img[fname]\n","                new_images.append(img_info)\n","\n","                img_id = img_info['id']\n","                if img_id in img_id_to_anns:\n","                    new_annotations.extend(img_id_to_anns[img_id])\n","            else:\n","                missing_count += 1\n","\n","        if missing_count > 0:\n","            print(f\"    Cảnh báo: Có {missing_count} ảnh trong tập {phase} không khớp tên trong file COCO.\")\n","\n","        new_json = {\n","            \"info\": info,\n","            \"licenses\": licenses,\n","            \"images\": new_images,\n","            \"annotations\": new_annotations,\n","            \"categories\": categories\n","        }\n","\n","        out_path = os.path.join(output_dir, f\"{phase}.json\")\n","        with open(out_path, 'w', encoding='utf-8') as f:\n","            json.dump(new_json, f, ensure_ascii=False)\n","\n","        print(f\"    Đã lưu: {out_path}\")\n","        print(f\"    Số lượng: {len(new_images)} ảnh, {len(new_annotations)} labels.\")\n","\n","MASTER_COCO_FILE = '/content/drive/MyDrive/New_BBox_Dataset/merged_coco_version/ver_6/merged_coco_v6_left_out_cha_mieng_fix_cha_ca.json'\n","OUTPUT_FOLDER = \"/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/ver_6/left_out_cha_mieng_fix_cha_ca/background_v5/\"\n","\n","create_coco_subsets(MASTER_COCO_FILE, datasets, OUTPUT_FOLDER)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nsavofPIMBtf","executionInfo":{"status":"ok","timestamp":1766835639243,"user_tz":-420,"elapsed":148,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"a2ec8564-3901-46e3-a8c2-11a07dbd339f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Đang đọc file gốc: /content/drive/MyDrive/New_BBox_Dataset/merged_coco_version/ver_6/merged_coco_v6_left_out_cha_mieng_fix_cha_ca.json ...\n","--> Đang xử lý tập: TRAIN\n","    Đã lưu: /content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/ver_6/left_out_cha_mieng_fix_cha_ca/background_v5/train.json\n","    Số lượng: 585 ảnh, 2449 labels.\n","--> Đang xử lý tập: VAL\n","    Đã lưu: /content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/ver_6/left_out_cha_mieng_fix_cha_ca/background_v5/val.json\n","    Số lượng: 77 ảnh, 365 labels.\n","--> Đang xử lý tập: TEST\n","    Đã lưu: /content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/ver_6/left_out_cha_mieng_fix_cha_ca/background_v5/test.json\n","    Số lượng: 76 ảnh, 323 labels.\n"]}]},{"cell_type":"markdown","source":["**Add BackGround Image to Train**"],"metadata":{"id":"ptHftMH50YyR"}},{"cell_type":"code","source":["with open('/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/ver_6/left_out_cha_mieng_fix_cha_ca/background_v5/train.json', 'r', encoding='utf-8') as f:\n","    data_train = json.load(f)"],"metadata":{"id":"9wF6RRoLuabi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def merge_coco_datasets(data_all, data_background):\n","\n","    bg_imgs = copy.deepcopy(data_background.get('images', []))\n","    bg_anns = copy.deepcopy(data_background.get('annotations', []))\n","\n","    max_img_id = max([img['id'] for img in data_all['images']]) if data_all['images'] else -1\n","    max_ann_id = max([ann['id'] for ann in data_all['annotations']]) if data_all['annotations'] else -1\n","\n","    img_id_map = {}\n","\n","    print(f\"Đang merge {len(bg_imgs)} ảnh và {len(bg_anns)} annotations...\")\n","\n","    for img in bg_imgs:\n","        old_id = img['id']\n","        max_img_id += 1\n","        new_id = max_img_id\n","\n","        img['id'] = new_id\n","        img_id_map[old_id] = new_id\n","\n","        data_all['images'].append(img)\n","\n","    for ann in bg_anns:\n","        max_ann_id += 1\n","        ann['id'] = max_ann_id\n","\n","        if ann['image_id'] in img_id_map:\n","            ann['image_id'] = img_id_map[ann['image_id']]\n","            data_all['annotations'].append(ann)\n","        else:\n","            print(f\"Warning: Bỏ qua annotation {ann['id']} vì không tìm thấy ảnh gốc ID {ann['image_id']}\")\n","\n","    print(f\"Hoàn tất! Tổng số ảnh hiện tại: {len(data_all['images'])}\")\n","    return data_all\n","\n","with open('/content/drive/MyDrive/New_BBox_Dataset/coco_annotation/cleaned/background_v3.json', 'r') as f: data_background = json.load(f)\n","\n","data_train = merge_coco_datasets(data_train, data_background)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88EwkeqDzQf6","executionInfo":{"status":"ok","timestamp":1766835682155,"user_tz":-420,"elapsed":266,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"0292e2b8-71ea-4a53-96f8-c11889d81c70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Đang merge 45 ảnh và 0 annotations...\n","Hoàn tất! Tổng số ảnh hiện tại: 634\n"]}]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/New_BBox_Dataset/train_test_split_version/ver_6/left_out_cha_mieng_fix_cha_ca/background_v5/train.json', 'w') as f: json.dump(data_train, f)"],"metadata":{"id":"KVhpKCdJz3HJ"},"execution_count":null,"outputs":[]}]}