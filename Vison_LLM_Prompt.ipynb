{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KhJ9C3GJkDR-TXWwir4YS_jKvuP119aW","timestamp":1765108672919},{"file_id":"1t0-Msf2tQZ8jzy5vi-YYDbLTr7UDXdKC","timestamp":1765098965366}],"gpuType":"L4","authorship_tag":"ABX9TyN7rTkdf79b520sqEQ/LCS9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install git+https://github.com/huggingface/transformers accelerate bitsandbytes qwen_vl_utils"],"metadata":{"id":"qv7_mz3HWY4k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1765340578366,"user_tz":-420,"elapsed":40232,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"25deacc0-c824-4fb7-f6a2-5ed8877c9240"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-ji_soyjg\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-ji_soyjg\n","  Resolved https://github.com/huggingface/transformers to commit 471d7ce9abbb3bc1b3bab673367378f9dbc3caac\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n","Collecting qwen_vl_utils\n","  Downloading qwen_vl_utils-0.0.14-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (3.20.0)\n","Collecting huggingface-hub<2.0,>=1.2.1 (from transformers==5.0.0.dev0)\n","  Downloading huggingface_hub-1.2.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (6.0.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2025.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (2.32.4)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.22.1)\n","Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.20.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (0.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==5.0.0.dev0) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n","Collecting av (from qwen_vl_utils)\n","  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from qwen_vl_utils) (11.3.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (2025.3.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.2.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (0.28.1)\n","Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.5.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==5.0.0.dev0) (2025.11.12)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers==5.0.0.dev0) (8.3.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (4.12.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers==5.0.0.dev0) (0.16.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n","Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading qwen_vl_utils-0.0.14-py3-none-any.whl (8.1 kB)\n","Downloading huggingface_hub-1.2.1-py3-none-any.whl (520 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.9/520.9 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-5.0.0.dev0-py3-none-any.whl size=10869362 sha256=52d699113eb414099b9b0ebcbab0eeace61ce82e01124cdd4d0873fd570ab3ef\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-841xt93p/wheels/49/a7/50/c9fdabbf10e51bb1256adb0c1a587fedd7184f5bad28d47fe3\n","Successfully built transformers\n","Installing collected packages: av, qwen_vl_utils, huggingface-hub, bitsandbytes, transformers\n","  Attempting uninstall: huggingface-hub\n","    Found existing installation: huggingface-hub 0.36.0\n","    Uninstalling huggingface-hub-0.36.0:\n","      Successfully uninstalled huggingface-hub-0.36.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.57.3\n","    Uninstalling transformers-4.57.3:\n","      Successfully uninstalled transformers-4.57.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 5.0.0.dev0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed av-16.0.1 bitsandbytes-0.48.2 huggingface-hub-1.2.1 qwen_vl_utils-0.0.14 transformers-5.0.0.dev0\n"]}]},{"cell_type":"markdown","source":["**LOAD DATASET**"],"metadata":{"id":"JpT_mJuTiHN8"}},{"cell_type":"code","source":["# !gdown ...... -O /content/data.zip"],"metadata":{"id":"Qq38b7a3iUMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!unzip \"/content/data.zip\" -d \"/content/data\""],"metadata":{"id":"Yv9ET4jyWozw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np"],"metadata":{"id":"y-197WLKX7HO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive', force_remount= True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yQxo2gn3YZBe","executionInfo":{"status":"ok","timestamp":1765340669103,"user_tz":-420,"elapsed":22992,"user":{"displayName":"Phạm Thanh Linh","userId":"06016909082113352084"}},"outputId":"43786e51-4a57-49e7-d1ae-8a990a59f5ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["**Apply AI Annotate Assisstance**"],"metadata":{"id":"pj1K3Nl5kh7y"}},{"cell_type":"code","source":["import torch\n","from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n","from qwen_vl_utils import process_vision_info\n","import json\n","import os\n","from tqdm import tqdm\n","\n","# --- 1. CẤU HÌNH INPUT / OUTPUT ---\n","img_folders = ['Suon', 'Cha_Ca', 'TOFU']\n","output_files = ['suon_metadata.json', 'chaca_metadata.json', 'tofu_metadata.json']\n","\n","BASE_DATA_PATH = '/content/data/'\n","BASE_OUTPUT_PATH = '/content/drive/MyDrive/Data MetaData/'\n","\n","os.makedirs(BASE_OUTPUT_PATH, exist_ok=True)\n","\n","# --- 2. LOAD MODEL\n","print(\"Đang cấu hình quantization...\")\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","print(\"Đang load Qwen2-VL-7B...\")\n","model = Qwen2VLForConditionalGeneration.from_pretrained(\n","    \"Qwen/Qwen2-VL-7B-Instruct\",\n","    torch_dtype=torch.bfloat16,\n","    attn_implementation=\"sdpa\",\n","    device_map=\"auto\",\n","    quantization_config=bnb_config\n",")\n","\n","processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\")\n","print(\"Load model thành công!\")\n","\n","def get_prompt_by_category(category_name):\n","    \"\"\"\n","    Trả về System Prompt phù hợp cho từng loại món ăn.\n","    Bạn cần định nghĩa lại các thuộc tính (Attributes) cho Sườn và Chả Cá.\n","    \"\"\"\n","\n","    prompt_tofu = \"\"\"\n","Role: You are a Computer Vision Data Specialist for Vietnamese Cuisine (Target: Tofu - Dau Hu).\n","Objective: Analyze the image to extract TWO distinct layers of metadata: (1) Food-specific attributes and (2) General Image attributes.\n","\n","INPUT: Image of Tofu.\n","OUTPUT: A single valid JSON object following the structure below.\n","\n","### 1. FOOD_ATTRIBUTES (Domain Specific - Tofu)\n","Analyze the physical state of the tofu:\n","- Morphology:\n","  - \"Block_Cube\": Standard square/rectangular block (intact).\n","\n","- Surface_Texture:\n","  - \"Fried_Rough\": Brown/Yellow skin, porous/bubbly texture.\n","  - \"Matte_Porous\": White/Ivory skin, matte/micro-porous texture.\n","\n","- Dish_Variant (Contextual State):\n","  - \"Plain_Dry_Item\":\n","      Description: \"Tofu blocks (either White or Fried) appearing alone on a plate, basket, or pan. No heavy sauce, no soup. Surface is relatively dry or just oily.\"\n","  - \"Sauce_Topping_Complex\":\n","      Description: \"Tofu is coated with THICK sauce (Tomato/Soy), glazed with oil (Scallion Oil), or stuffed with meat. Liquid is viscous/sticky, not watery.\"\n","  - \"Soup_Broth_Context\":\n","      Description: \"Tofu is submerged or floating in THIN/WATERY liquid (Broth/Soup/Bun). Usually accompanied by liquid, vegetables, or noodles.\"\n","\n","### 2. IMAGE_ATTRIBUTES (General Vision - Standardized)\n","Analyze the photographic conditions (Must match standard project schema):\n","- Lighting_Condition:\n","  - \"Natural_Daylight\": Balanced white light.\n","  - \"Artificial_Warm\": Yellow/Orange tint (Indoor/Restaurant).\n","- Background_Complexity:\n","  - \"Clean_Solid\": Single color plate/background.\n","  - \"Simple_Table\": 1-2 items nearby.\n","  - \"Cluttered_Messy\": Busy scene (>3 items), hard to isolate.\n","- Occlusion_Level:\n","  - \"None\": Fully visible.\n","  - \"Low\": <20% covered (e.g., some scallions).\n","  - \"Medium\": 20-50% covered.\n","  - \"High\": >50% covered (hard to recognize).\n","\n","### 3. PLANNING_META (Scenario Mapping)\n","Map the image to the Project CSV Plan based on the DOMINANT feature:\n","- \"1_Baseline\": High contrast, clear view (Fried on White / White on Dark).\n","- \"2_Low_Contrast\": Camouflaged (White Tofu on White Plate/Board).\n","- \"3_Texture_Macro\": Close-up focusing on pores or smoothness.\n","- \"4_Wet_Sauce\": Floating in soup, or covered in Tomato sauce.\n","- \"5_Deformed_Cut\": Broken pieces, cut dices, or physically damaged.\n","- \"6_Interaction\": Being fried in oil, held by chopsticks, or handled.\n","- \"7_Specularity_Light\": Extreme lighting, flash, or high reflection.\n","\n","RESPONSE FORMAT: JSON ONLY. NO MARKDOWN.\n","\"\"\"\n","\n","    prompt_suon = \"\"\"\n","Role: Computer Vision Specialist for Vietnamese Cuisine (Suon Nuong).\n","    Task: Analyze the image and extract metadata into a JSON object.\n","\n","    ### KNOWLEDGE BASE (Use these criteria to decide):\n","\n","    1. MORPHOLOGY (Shape):\n","       - \"Planar_Loin_Structure\": Flat slab, dense lean meat (Cot Let).\n","         * Variations: \"Whole_Slab\" (Curved rib bone on edge), \"Sliced_Strips\" (Uniform rectangular strips).\n","       - \"Volumetric_Rib_Chunk\": 3D blocky/tubular shape (Suon Non).\n","         * Internal_Details: \"Embedded_Bone_Cartilage\" (Center bone/cartilage), \"Interspersed_Texture\" (Marbled fat).\n","\n","    2. SURFACE TEXTURE:\n","       - \"Dry_Charred_Matte\": Low reflection, visible grill marks, burnt edges.\n","       - \"Oily_Glazed_Specular\": High reflection, wet/sticky look (Honey/Scallion oil).\n","\n","    3. DISH CONTEXT:\n","       - \"Com_Tam_Assembly\": Placed on broken rice.\n","       - \"Isolated_Item\": Alone on plate/grill.\n","\n","    4. PLANNING META (Scenario Mapping):\n","       - \"1_Geometry_Shape\": Clear view of bone/cartilage.\n","       - \"2_Com_Tam_Full_Set\": Full context with Rice + Egg + Bi + Cha.\n","       - \"3_Mo_Hanh_Occlusion\": Covered by Scallion Oil.\n","       - \"4_Grill_Marks_Char\": Focus on char/burn marks.\n","       - \"5_Glaze_Specularity\": Focus on wet/shiny sauce.\n","       - \"6_Lighting_Difficult\": Bad lighting/shadows.\n","       - \"7_Broken_Sliced\": Cut pieces/deformed.\n","\n","    ### REQUIRED OUTPUT FORMAT (JSON ONLY):\n","    Fill in the values based on the Knowledge Base above. Do NOT include descriptions.\n","\n","    {\n","      \"food_attributes\": {\n","        \"morphology\": {\n","          \"category\": \"...\",\n","          \"detail_variation\": \"...\"\n","        },\n","        \"surface_texture\": \"...\",\n","        \"dish_context\": \"...\"\n","      },\n","      \"image_attributes\": {\n","        \"lighting_condition\": \"Natural_Daylight OR Artificial_Warm\",\n","        \"background_complexity\": \"Clean_Solid OR Simple_Table OR Cluttered_Messy\",\n","        \"occlusion_level\": \"None OR Low OR Medium OR High\"\n","      },\n","      \"planning_meta\": {\n","        \"scenario_mapping\": \"...\"\n","      }\n","    }\n","\"\"\"\n","\n","    prompt_chaca = \"\"\"\n","Role: You are a Computer Vision Data Specialist for Vietnamese Cuisine (Target: Cha Ca - Fish Cake).\n","Objective: Analyze the image to extract structured metadata, strictly adhering to the morphological dependency rules.\n","\n","INPUT: Image of Cha Ca.\n","OUTPUT: A single valid JSON object following the structure below.\n","\n","### 1. FOOD_ATTRIBUTES (Domain Specific)\n","Analyze the physical state of the food itself:\n","\n","A. Morphology (Primary Classifier):\n","   - \"Whole_Block\": Intact piece, outer skin covers all sides (No meat visible).\n","   - \"Sliced_Section\": Cut piece exposing inner meat (High color contrast between dark skin and light meat).\n","\n","B. Surface_Texture (Apply Priority Rule):\n","   CRITICAL LOGIC:\n","   1. IF Morphology is \"Whole_Block\" -> Texture MUST be \"Wrinkled_Skin\".\n","   2. IF Morphology is \"Sliced_Section\" -> You MUST ignore the outer skin and classify the EXPOSED INNER MEAT.\n","\n","   - \"Wrinkled_Skin\": [VALID ONLY IF Whole_Block] Fried outer layer, brown/yellow, rough/leathery.\n","   - \"Porous_Inner\": [VALID ONLY IF Sliced_Section] The exposed inner meat has visible air holes, sponge-like texture (white/grey).\n","   - \"Smooth_Cut\": [VALID ONLY IF Sliced_Section] The exposed inner meat is solid, dense, and smooth with minimal pores (white/grey).\n","\n","C. Interaction_State (Contextual Physics):\n","   - \"Solid_Dry_Stacked\":\n","       Description: \"Item is on a dry surface (plate/cutting board) or held by hand. No liquid/sauce interaction.\"\n","       Visual_Cue: \"Clean boundaries, distinct shadows on surface, items often overlapping or piled.\"\n","   - \"Surface_Topping_Arrangement\":\n","       Description: \"Item matches 'Bun Ca' style. Placed ON TOP of a solid base (noodles), maintaining a specific geometric layout. Only the bottom touches the liquid.\"\n","       Visual_Cue: \"High visibility, organized placement, distinct separation from the liquid level.\"\n","   - \"Shallow_Braised_Bathing\":\n","       Description: \"Item is resting on the bottom of a container (pan/plate), surrounded by a THICK/SHALLOW sauce (not deep broth). Top surface is exposed but may be coated with sauce/oil.\"\n","       Visual_Cue: \"Thick liquid texture (viscous), items are stationary, often garnished with sprinkles (scallions/dill) sticking to the wet surface.\"\n","   - \"Partially_Submerged_Floating\":\n","       Description: \"Item is bobbing freely in DEEP, THIN liquid (broth/water). No solid base underneath.\"\n","       Visual_Cue: \"Meniscus effect around edges, random orientation.\"\n","   - \"Fully_Submerged_Deep\":\n","       Description: \"Item is completely under liquid.\"\n","\n","### 2. IMAGE_ATTRIBUTES (General Vision)\n","Analyze the photographic conditions:\n","- Lighting_Condition:\n","   - \"Natural_Daylight\": Balanced white light.\n","   - \"Artificial_Warm\": Yellow/Orange tint (Indoor/Restaurant).\n","\n","- Background_Complexity:\n","   - \"Clean_Solid\": Single color plate/background.\n","   - \"Simple_Table\": 1-2 items nearby.\n","   - \"Cluttered_Messy\": Busy scene (>3 items), hard to isolate.\n","\n","- Occlusion_Level:\n","   - \"None\": Fully visible.\n","   - \"Low\": <20% covered (e.g., some scallions).\n","   - \"Medium\": 20-50% covered.\n","   - \"High\": >50% covered (hard to recognize).\n","\n","### 3. PLANNING_META (Scenario Mapping)\n","Map the image to one of these groups based on the dominant feature:\n","- \"1_Baseline\": Clean background, standard view.\n","- \"2_In_The_Wild\": In soup/broth context.\n","- \"3_Complex_BG\": Cluttered table.\n","- \"4_Occlusion\": Herbs/Sauce covering object.\n","- \"5_Interaction\": Holding/Eating action.\n","- \"6_Dense_Cluster\": Piled up (Solid/Dry).\n","- \"7_Lighting_Var\": Difficult lighting.\n","\n","RESPONSE FORMAT: JSON ONLY. NO MARKDOWN.\n","\"\"\"\n","\n","    if \"tofu\" in category_name.lower():\n","        return prompt_tofu\n","    elif \"suon\" in category_name.lower():\n","        return prompt_suon\n","    elif \"cha_ca\" in category_name.lower() or \"chaca\" in category_name.lower():\n","        return prompt_chaca\n","    else:\n","        # Fallback prompt nếu không khớp tên folder\n","        return prompt_tofu\n","\n","def analyze_image_qwen(image_path, img_id, specific_prompt):\n","    messages = [\n","        {\n","            \"role\": \"user\",\n","            \"content\": [\n","                {\"type\": \"image\", \"image\": image_path},\n","                {\"type\": \"text\", \"text\": specific_prompt},\n","            ],\n","        }\n","    ]\n","\n","    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n","    image_inputs, video_inputs = process_vision_info(messages)\n","\n","    inputs = processor(\n","        text=[text],\n","        images=image_inputs,\n","        videos=video_inputs,\n","        padding=True,\n","        return_tensors=\"pt\",\n","    )\n","    inputs = inputs.to(\"cuda\")\n","\n","    generated_ids = model.generate(**inputs, max_new_tokens=512, temperature=0.1)\n","\n","    generated_ids_trimmed = [\n","        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n","    ]\n","    output_text = processor.batch_decode(\n","        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n","    )[0]\n","\n","    try:\n","        cleaned_text = output_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n","        start = cleaned_text.find('{')\n","        end = cleaned_text.rfind('}') + 1\n","\n","        if start != -1 and end != -1:\n","            json_str = cleaned_text[start:end]\n","            data = json.loads(json_str)\n","            data[\"id_anh\"] = img_id\n","            return data\n","        else:\n","            return None\n","    except Exception as e:\n","        print(f\"Lỗi xử lý {img_id}: {e}\")\n","        return None\n","\n","def main():\n","    for folder_name, output_filename in zip(img_folders, output_files):\n","\n","        current_img_dir = os.path.join(BASE_DATA_PATH, folder_name)\n","        current_out_path = os.path.join(BASE_OUTPUT_PATH, output_filename)\n","\n","        print(f\"\\n{'='*40}\")\n","        print(f\"Đang xử lý Folder: {folder_name}\")\n","        print(f\"Đường dẫn ảnh: {current_img_dir}\")\n","        print(f\"File lưu: {current_out_path}\")\n","\n","        if not os.path.exists(current_img_dir):\n","            print(f\"Không tìm thấy folder: {current_img_dir} -> Bỏ qua.\")\n","            continue\n","\n","        files = [f for f in os.listdir(current_img_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n","        if len(files) == 0:\n","            print(f\"Folder {folder_name} rỗng -> Bỏ qua.\")\n","            continue\n","\n","        current_prompt = get_prompt_by_category(folder_name)\n","\n","        results = []\n","        print(f\"Bắt đầu quét {len(files)} ảnh trong {folder_name}...\")\n","\n","        for filename in tqdm(files, desc=f\"Processing {folder_name}\"):\n","            path = os.path.join(current_img_dir, filename)\n","            try:\n","                res = analyze_image_qwen(path, filename, current_prompt)\n","                if res:\n","                    results.append(res)\n","            except Exception as e:\n","                print(f\"Lỗi file {filename}: {e}\")\n","\n","        with open(current_out_path, 'w', encoding='utf-8') as f:\n","            json.dump(results, f, indent=4, ensure_ascii=False)\n","        print(f\"Đã lưu xong {len(results)} kết quả vào {output_filename}\")\n","\n","    print(\"\\nHOÀN TẤT TẤT CẢ CÁC FOLDER!\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"CamgWORkmN_c"},"execution_count":null,"outputs":[]}]}